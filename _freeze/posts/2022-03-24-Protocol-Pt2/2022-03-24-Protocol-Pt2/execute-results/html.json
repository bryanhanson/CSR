{
  "hash": "887c25917d75091ad3289c1b0209bad1",
  "result": {
    "markdown": "---\ntitle: \"Metabolic Phenotyping Protocol Part 2\"\ndescription: \"Implementing the Statistical Analysis in Metabolic Phenotyping Protocol of Blaise *et al.*\"\ndate: \"2022-03-24\"\ncategories: [R, ChemoSpec, Metabolomics]\nbibliography: REFS.bib\n---\n\n::: {.cell}\n\n:::\n\nPart 1 of this series is [here](https://chemospec.org/posts/2022-02-01-Protocol-Pt1/).\n\nIf you aren't familiar with `ChemoSpec`, you might wish to look at the introductory [vignette](https://bryanhanson.github.io/ChemoSpec/articles/ChemoSpec.html) first.\n\n*In this series of posts we are following the protocol as described in the printed publication closely [@Blaise2021].  The authors have also provided a [Jupyter notebook](https://github.com/Gscorreia89/chemometrics-tutorials).  This is well worth your time, even if Python is not your preferred lanaguage, as there are additional examples and discussion for study.*\n\n# Read in the Data\n\nI saved the `Spectra` object we created in Part 1 so we can read it and remind ourselves of what's in it. Due to the compression in R's `save` function the data takes up 4.9 Mb on disk.  The original csv files total about 62 Mb.\n\n::: {.cell layout-align=\"center\" hash='2022-03-24-Protocol-Pt2_cache/html/getData_5c76d8f7c10699917b5f7feda26b160b'}\n\n```{.r .cell-code}\nlibrary(\"ChemoSpec\")\nload(\"Worms.Rdata\")  # restores the 'Worms' Spectra object\nsumSpectra(Worms)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n C. elegans metabolic phenotyping study (Blaise 2007) \n\n\tThere are 139 spectra in this set.\n\tThe y-axis unit is intensity.\n\n\tThe frequency scale runs from\n\t8.9995 to 5e-04 ppm\n\tThere are 8600 frequency values.\n\tThe frequency resolution is\n\t0.001 ppm/point.\n\n\tThis data set is not continuous\n\talong the frequency axis.\n\tHere are the data chunks:\n\n  beg.freq end.freq   size beg.indx end.indx\n1   8.9995   5.0005 -3.999        1     4000\n2   4.5995   0.0005 -4.599     4001     8600\n\n\tThe spectra are divided into 4 groups: \n\n   group no.     color symbol alt.sym\n1 Mut_L2  32 #FB0D16FF      0      m2\n2 Mut_L4  33 #FFC0CBFF     15      m4\n3  WT_L2  34 #511CFCFF      1      w2\n4  WT_L4  40 #2E94E9FF     16      w4\n\n\n*** Note: this is an S3 object\nof class 'Spectra'\n```\n:::\n:::\n\n# Exploratory Data Analysis\n\nWe will follow the steps described in the published protocol closely.\n\n## Normalization & Scaling\n\nApply PQN normalization; scaling in `ChemoSpec` is applied at the PCA stage (next).\n\n::: {.cell layout-align=\"center\" hash='2022-03-24-Protocol-Pt2_cache/html/norm_56aa7b023a689faf5f4672ad1706bd85'}\n\n```{.r .cell-code}\nWorms <- normSpectra(Worms)  # PQN is the default\n```\n:::\n\n## PCA\n\nConduct classical PCA using autoscaling.[^1]  Note that `ChemoSpec` includes several different variants of PCA, each with scaling options.  See the introductory vignette for more details.  For more about what PCA is and how it works, please see the [LearnPCA](https://bryanhanson.github.io/LearnPCA/) package.\n\n::: {.cell layout-align=\"center\" hash='2022-03-24-Protocol-Pt2_cache/html/pca_1a1da64fbdebcc58e9e3bb45e7af0a25'}\n\n```{.r .cell-code}\nc_pca <- c_pcaSpectra(Worms, choice = \"autoscale\")  # no scaling is the default\n```\n:::\n\n### Components to Retain\n\nA key question at this stage is how many components are needed to describe the data set.  Keep in mind that this depends on the choice of scaling. @fig-screeAlt and @fig-screeTrad are two different types of scree plots, which show the residual variance.  This is the R^2^~x~ value in the protocol (see protocol Figure 7a).  Another approach to answering this question is to do a cross-validated PCA.[^3]  The results are shown in @fig-cv-pca.  These are the Q^2^~x~ values in protocol Figure 7a.  All of these ways of looking at the variance explained suggest that retaining three or possibly four PCs is adequate.\n\n::: {.cell layout-align=\"center\" hash='2022-03-24-Protocol-Pt2_cache/html/fig-screeAlt_1abc3fdd975a4c23fc680b69270a7f28'}\n\n```{.r .cell-code}\nplotScree(c_pca)\n```\n\n::: {.cell-output-display}\n![Scree plot (recommended style).](2022-03-24-Protocol-Pt2_files/figure-html/fig-screeAlt-1.png){#fig-screeAlt fig-align='center' width=80%}\n:::\n:::\n\n::: {.cell layout-align=\"center\" hash='2022-03-24-Protocol-Pt2_cache/html/fig-screeTrad_83fd39cd7b0de03daf6f9d256e79bf15'}\n\n```{.r .cell-code}\nplotScree(c_pca, style = \"trad\")\n```\n\n::: {.cell-output-display}\n![Scree plot (traditional style).](2022-03-24-Protocol-Pt2_files/figure-html/fig-screeTrad-1.png){#fig-screeTrad fig-align='center' width=80%}\n:::\n:::\n\n::: {.cell layout-align=\"center\" hash='2022-03-24-Protocol-Pt2_cache/html/fig-cv-pca_ce8857bd5320503e2da81e49461bb359'}\n\n```{.r .cell-code}\ncv_pcaSpectra(Worms, choice = \"autoscale\", pcs = 10)\n```\n\n::: {.cell-output-display}\n![Scree plot using cross validation.](2022-03-24-Protocol-Pt2_files/figure-html/fig-cv-pca-1.png){#fig-cv-pca fig-align='center' width=80%}\n:::\n:::\n\n### Score Plots\n\nNext, examine the score plots (@fig-scores12, @fig-scores23).  In these plots, each data point is colored by its group membership (keep in mind this is completely independent of the PCA calculation).  In addition, robust confidence ellipses are shown for each group.  Inspection of these plots is one way to identify potential outliers. The other use is of course to see if the sample classes separate, and by how much.\n\nExamination of these plots shows that separation by classes has not really been achieved using autoscaling. In @fig-scores12 we see four clear outlier candidates (samples 37, 101, 107, and 118).  In @fig-scores23 we see some of these samples and should probably add sample 114 for a total of five candidates.\n\n::: {.cell layout-align=\"center\" hash='2022-03-24-Protocol-Pt2_cache/html/fig-scores12_ac627f961d8e9ce3c512c07b3a2f1ca1'}\n\n```{.r .cell-code}\np <- plotScores(Worms, c_pca, pcs = 1:2, ellipse = \"rob\", tol = 0.02)\np\n```\n\n::: {.cell-output-display}\n![Score plot for PCs 1 and 2. Compare to protocol figure 7a.](2022-03-24-Protocol-Pt2_files/figure-html/fig-scores12-1.png){#fig-scores12 fig-align='center' width=80%}\n:::\n:::\n\n::: {.cell layout-align=\"center\" hash='2022-03-24-Protocol-Pt2_cache/html/fig-scores23_7c8c513b910ae960f3efa4286710f901'}\n\n```{.r .cell-code}\np <- plotScores(Worms, c_pca, pcs = 2:3, ellipse = \"rob\", leg.loc = \"topright\", tol = 0.02)\np\n```\n\n::: {.cell-output-display}\n![Score plot for PCS 2 and 3.](2022-03-24-Protocol-Pt2_files/figure-html/fig-scores23-1.png){#fig-scores23 fig-align='center' width=80%}\n:::\n:::\n\nTo label more sample points, you can increase the value of the argument `tol`.\n\n### Outliers\n\nThe protocol recommends plotting Hotelling's *T*^2^ ellipse for the entire data set; this is not implemented in `ChemoSpec` but we can easily do it if we are using `ggplot2` plots (which is the default in `ChemoSpec`).  We need the `ellipseCoord` function from the `HotellingsEllipse` package.[^2]\n\n::: {.cell layout-align=\"center\" hash='2022-03-24-Protocol-Pt2_cache/html/fig-hotelling1_eadb3ae98074dc823883c80a04b1c9a4'}\n\n```{.r .cell-code}\nsource(\"ellipseCoord.R\")\nxy_coord <- ellipseCoord(as.data.frame(c_pca$x), pcx = 1, pcy = 2, conf.limit = 0.95,\n    pts = 500)\np <- plotScores(Worms, c_pca, which = 1:2, ellipse = \"none\", tol = 0.02)\np <- p + geom_path(data = xy_coord, aes(x = x, y = y)) + scale_color_manual(values = \"black\")\np\n```\n\n::: {.cell-output-display}\n![Score plot for PCs 1 and 2 with Hotelling's *T*^2^ ellipse. Compare to protocol figure 7a.](2022-03-24-Protocol-Pt2_files/figure-html/fig-hotelling1-1.png){#fig-hotelling1 fig-align='center' width=80%}\n:::\n:::\n\nWe can see many of the same outliers by this approach as we saw in @fig-scores12 and @fig-scores23.\n\n\nAnother way to identify outliers is to use the approach described in @Filzmoser2009 section 3.7.3.  @fig-diagOD and  @fig-diagSD give the plots. Please see Filzmoser for the details, but any samples that are above the plotted threshold line are candidate outliers, and any samples above the threshold in *both* plots should be looked at very carefully.  Though we are using classical PCA, Filzmoser recommends using these plots with robust PCA.  These plots are a better approach than \"eye balling it\" on the score plots.\n\n::: {.cell layout-align=\"center\" hash='2022-03-24-Protocol-Pt2_cache/html/fig-diagOD_ef9c479ac399ac49334d26d78c1eb1f4'}\n\n```{.r .cell-code}\np <- pcaDiag(Worms, c_pca, plot = \"OD\")\np\n```\n\n::: {.cell-output-display}\n![Orthogonal distance plot based on the first three PCs.](2022-03-24-Protocol-Pt2_files/figure-html/fig-diagOD-1.png){#fig-diagOD fig-align='center' width=80%}\n:::\n:::\n\n::: {.cell layout-align=\"center\" hash='2022-03-24-Protocol-Pt2_cache/html/fig-diagSD_ad3694ee8233f729b195eff1fae86129'}\n\n```{.r .cell-code}\np <- pcaDiag(Worms, c_pca, plot = \"SD\")\np\n```\n\n::: {.cell-output-display}\n![Score distance plot based on the first three PCs.](2022-03-24-Protocol-Pt2_files/figure-html/fig-diagSD-1.png){#fig-diagSD fig-align='center' width=80%}\n:::\n:::\n\nComparison of these plots suggest that samples 37, 101, 107, 114 and 118 are likely outliers.  These spectra should be examined to see if the reason for their outlyingness can be deduced. If good reason can be found, they can be removed as follows.[^4]\n\n::: {.cell layout-align=\"center\" hash='2022-03-24-Protocol-Pt2_cache/html/removeOutliers_7e075fd15a434d1645e31807799fe6c2'}\n\n```{.r .cell-code}\nWorms2 <- removeSample(Worms, rem.sam = c(\"37_\", \"101_\", \"107_\", \"114_\", \"118_\"))\n```\n:::\n\nAt this point one should repeat the PCA, score plots and diagnostic plots to get a good look at how removing these samples affected the results. Those tasks are left to the reader.\n\n<!-- One thing the protocol does not explicitly discuss is an inspection of the loadings.  This is useful in order to see if any particular frequencies are driving the separation of the samples in the score plot. For the sake of completeness, we'll go ahead and plot the loadings. See @fig-loadings. From this plot it is clear that the peaks above $\\delta$ 5.0 are not contributing much to differentiating the samples.  One could consider removing these peaks from the analysis, but we'll leave them for now. -->\n\n::: {.cell layout-align=\"center\" hash='2022-03-24-Protocol-Pt2_cache/html/fig-loadings_5710d6cefea5a3943156f47724d89483'}\n\n:::\n\nWe will continue in the next post with a discussion of loadings.\n\n::: {.cell layout-align=\"center\" hash='2022-03-24-Protocol-Pt2_cache/html/saveResults_aaa0bfc31d5d7bfe5377174c43f0014f'}\n\n:::\n---\n\nThis post was created using `ChemoSpec` version 6.1.3 and `ChemoSpecUtils` version 1.0.0.\n\n[^1]: Without scaling, the largest peaks will drive the separation in the scores plot.\n[^2]: We are sourcing in a corrected version of the function, as the CRAN version has a small [error](https://github.com/ChristianGoueguel/HotellingEllipse/issues/2) in it.\n[^3]: Be sure you have `ChemoSpec` 6.1.3 or higher, as `cv_pcaSpectra` had a bug in it!  One benefit of writing these posts is finding lame bugs...\n[^4]: The [Jupyter notebook](https://github.com/Gscorreia89/chemometrics-tutorials) has details about this.",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": null
  }
}